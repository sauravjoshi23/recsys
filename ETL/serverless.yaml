service: recsys-aws-glue-crawler

useDotenv: true

provider:
  name: aws
  region: us-west-1

plugins:
  - serverless-glue

Glue:
  bucketDeploy: ${env:GLUE_BUCKET}
  tempDirBucket: ${env:GLUE_BUCKET_TEM}
  tempDirS3Prefix: 'temp/'
  jobs:
    - name: ${env:JOB_NAME}
      scriptPath: ${env:GLUE_SCRIPT_PYTHON_FILE_NAME}
      type: spark
      glueVersion: "python3-3.0"
      role: ${env:GLUE_ROLE_ARN}
      MaxConcurrentRuns: 3
      DefaultArguments:
        jobBookmarkOption: "job-bookmark-enable"
        customArguments:
          job-bookmark-option: "job-bookmark-enable"
      tempDir: true
      WorkerType: Standard
      NumberOfWorkers: 3
      Timeout: 2880
      MaxRetries: 1
      SupportFiles:
        - local_path: ${env:LOCAL_PATH}
          s3_bucket: ${env:GLUE_BUCKET}
          s3_prefix: ${env:S3_PREFIX_GLUE_SCRIPT}
          execute_upload: True

resources:
  Resources:
    GlueDatabase:
      Type: AWS::Glue::Database
      Properties:
        CatalogId: ${env:ACCOUNT}
        DatabaseInput:
          Name: ${env:DB_NAME}

    TableGlueCrawler:
      Type: AWS::Glue::Crawler
      Properties:
        DatabaseName: ${env:DB_NAME}
        Name: ${env:CRAWLER_NAME}
        RecrawlPolicy:
          RecrawlBehavior: CRAWL_EVERYTHING
        Role: ${env:GLUE_ROLE_ARN}
        SchemaChangePolicy:
          DeleteBehavior: DEPRECATE_IN_DATABASE
        Classifiers:
          - ${env:CUSTOM_CLASSIFIER}
        Targets:
          S3Targets:
            - Path: ${env:CRAWLER_TARGET_PATH}